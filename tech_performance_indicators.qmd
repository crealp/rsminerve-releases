# Performance indicators {#sec-tech_performance_indicators}

The indicators calculated by the Comparator object are based on observed and simulated values. Since the Comparator object is able to compare variables of type 
flow, height, altitude, power and True/False, the descriptions below only refer to these 2 variables.

## Nash coefficient {#sec-tech_performance_indicators_nash}

The Nash-Sutcliffe criteria [@nash_river_1970] is used to assess the predictive power of hydrological models [@ajami_calibration_2004; @schaefli_conceptual_2005;
@jordan_modeprevision_2007; @viviroli_continuous_2009; @garcia_hernandez_flood_2011]. It is defined as presented in @eq-IND1.

$$
Nash = 1 - \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})^{2}}}{\sum_{t = t_{i}}^{t_{f}}{(X_{ref,t} - {\overline{X}_{ref}})^{2}}}
$$ {#eq-IND1}

with $Nash$: Nash-Sutcliffe model efficiency coefficient \[-\]; $X_{sim,t}$: simulated variable (discharge \[L^3^/T\] or height \[L\]) at time $t$; $X_{ref,t}$ : 
observed variable (discharge \[L^3^/T\] or height \[L\]) at time $t$; $\overline{X}_{ref}$: average observed variable (discharge \[L^3^/T\] or height \[L\]) for the considered period.

It varies from -∞ to 1, with 1 representing the best performance of the model and zero the same performance than assuming the average of all the observations at each time step.

## Nash coefficient for logarithm values {#sec-tech_performance_indicators_nashlog}

The Nash-Sutcliffe coefficient for logarithm flow values ($Nash-ln$) is used to assess the hydrological models performance for low values [@krause_comparison_2005; @nobrega_uncertainty_2011].
It is defined as presented in @eq-IND2.

$$
\text{Nash-ln} = 1 - \frac{\sum_{t = t_{i}}^{t_{f}}{(ln(X_{sim,t}) - ln(X_{ref,t}))^{2}}}{\sum_{t = t_{i}}^{t_{f}}{(ln(X_{ref,t}) - ln({\overline{X}_{ref}}))^{2}}}
$$ {#eq-IND2}
  
with $Nash-ln$: Nash-Sutcliffe coefficient for log values \[-\].

It varies from -∞ to 1, with 1 representing the best performance of the model.

## Pearson Correlation Coefficient {#sec-tech_performance_indicators_pearson}

The Pearson correlation coefficient shows the covariability of the simulated and observed values without penalizing for bias [@aghakouchak_application_2010; @wang_monthly_2011]. 
It is defined as presented in @eq-IND3.

$$
Pearson = \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - {\overline{X}_{sim}}) \cdot (X_{ref,t} - {\overline{X}_{ref}})}}{\sqrt{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - {\overline{X}_{sim}})^{2}} \cdot \sum_{t = t_{i}}^{t_{f}}{(X_{ref,t} - {\overline{X}_{ref}})^{2}}}}
$$ {#eq-IND3}

with $Pearson$: Pearson Correlation Coefficient \[-\]; ${\overline{X}_{sim}}$: average simulated variable (discharge \[L^3^/T\] or height \[L\]) for the considered period.

It varies from -1 to 1, with 1 representing the best performance of the model.

## Kling-Gupta Efficiency {#sec-tech_performance_indicators_klinggupta}

The Kling-Gupta efficiency [@gupta_decomposition_2009] provides an indicator which facilitates the global analysis based on different components (correlation, bias and variability) 
for hydrological modelling issues.

@kling_runoff_2012 proposed a revised version of this indicator, to ensure that the bias and variability ratios are not cross-correlated. This update is proposed as indicator 
in RS MINERVE (@eq-IND4):

$$
KGE' = 1 - \sqrt{(r - 1)^{2} + (\beta - 1)^{2} + (\gamma - 1)^{2}}
$$ {#eq-IND4}

$$
\beta = \frac{\mu_{s}}{\mu_{o}}
$$ {#eq-IND5}

$$
\gamma = \frac{{CV}_{s}}{{CV}_{o}} = \frac{\sigma_{s}/\mu_{s}}{\sigma_{o}/\mu_{o}}
$$ {#eq-IND6}

with $KGE'$: modified KGE-statistic \[-\]; $r$: correlation coefficient between simulated and reference values \[-\]; $\beta$: bias ratio \[-\]; $\gamma$: variability ratio \[-\]; 
$\mu$: mean discharge \[L^3^/T\]; $CV$: coefficient of variation \[-\]; $\sigma$: standard deviation of discharge \[L^3^/T\]; the indices $s$ and $o$ indicate respectively simulated 
and observed discharge values.

It varies from 0 to 1, with 1 representing the best performance.

## Bias Score {#sec-tech_performance_indicators_biasscore}

The Bias Score ($BS$) is a symmetric estimation of the match between the average simulation and average observation [@wang_monthly_2011]. It is defined as presented in @eq-IND7.

$$
BS = 1 - \bigg( max \Big(\frac{{\overline{X}}_{sim}}{{\overline{X}}_{ref}};\frac{{\overline{X}}_{ref}}{{\overline{X}}_{sim}} \Big) - 1 \bigg)^2
$$ {#eq-IND7}

with $BS$: Bias Score \[-\].

It varies from -∞ to 1, with 1 representing the best performance of the model.

## Relative Root Mean Square Error {#sec-tech_performance_indicators_rrmse}

The Relative Root Mean Square Error ($RRMSE$) is defined as the RMSE normalized to the mean of the observed values [@feyen_application_2000; @el_nasr_modelling_2005; @heppner_adding_2006]
and is presented in @eq-IND8.

$$
RRMSE = \frac{\sqrt{\frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})^{2}}}{n}}}{{\overline{X}}_{ref}}
$$ {#eq-IND8}

with $RRMSE$: relative $RMSE$ \[-\]; $n$: number of values \[-\].

It varies from 0 to +∞. The smaller $RRMSE$, the better the model performance is.

## Relative Volume Bias {#sec-tech_performance_indicators_rvb}

The Relative Volume Bias ($RVB$), sometimes called differently, corresponds in this case to the relative error between the simulated and the observed volumes during the studied period 
[@ajami_calibration_2004; @schaefli_conceptual_2005; @moriasi_model_2007; @aghakouchak_application_2010] according to @eq-IND9. This indicator is envisaged for the comparison between 
observed and simulated discharges.

$$
RVB = \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})}}{\sum_{t = t_{i}}^{t_{f}}{(X_{ref,t})}}
$$ {#eq-IND9}

with $RVB$: relative volume bias between forecast and observation for the considered period \[-\]; $X$ usually corresponding to the discharge variable.

The $RVB$ varies from -1 to +∞. An index near to zero indicates a good performance of the simulation. Negative values are returned when simulated variable is, in average, smaller than 
the average of the observed one (deficit model), while positive values mean the opposite (overage model).

## Normalized Peak Error {#sec-tech_performance_indicators_npe}

The Normalized Peak Error ($NPE$) indicates the relative error between the simulated and the observed maximum values [@masmoudi_performance_1993; @sun_flood_2000; @ajami_calibration_2004; @gabellani_propagation_2007].
It is computed according to @eq-IND10 to @eq-IND12.

$$
NPE = \frac{S_{\max} - R_{\max}}{R_{\max}}
$$ {#eq-IND10}

$$
S_{\max} = \overset{t_{f}}{\underset{t = t_{i}}{\vee}}Q_{sim,t}
$$ {#eq-IND11}

$$
R_{\max} = \overset{t_{f}}{\underset{t = t_{i}}{\vee}}Q_{ref,t}
$$ {#eq-IND12}

with $NPE$: relative error between simulated and observed peak value \[-\]; $S_{max}$: maximum simulated value (discharge \[L^3^/T\] or height \[L\]) for the studied period; $R_{max}$ : 
maximum observed value (discharge \[L^3^/T\] or height \[L\]) for the studied period.

The NPE varies from -1 to +∞. Negative values are returned when maximum simulated value is below the observed one, while positive values mean the opposite. Values near to zero indicate a 
good performance of simulated peaks regarding observed ones.

:::{.callout-warning}
The indicator is computed over the entire simulation period and the absolute maximum of the simulated and the observed peaks are considered! This indicator should therefore be used with 
care when simulating over long periods of time.
:::

## Peirce Skill Score {#sec-tech_performance_indicators_pierce}

The Peirce Skill Score ($PSS$) indicates the performance of the model to reproduce the overrun of a threshold [@peirce_numerical_1884; @manzato_note_2007]. Based on a contingency table definging the 
number of cases where the simulation and the obseration exceed or not the threshold, the $PSS$ is computed according to @eq-IND13.

$$
PSS = \frac{ad - bc}{(a + c)(b + d)}
$$ {#eq-IND13}

with $a$: the number of cases when both simulation and observation exceed the threshold defined in the Comparator (event); $b$: the number of cases when the simulation exceeds the threshold 
but not the obseration (false); $c$: the number of cases when the observation exceeds the threshold but not the simulation (miss); $d$: the number of cases when both simulation and obseration 
are below the threshold (no event).

:::{.callout-note}
If the denominerator equals 0 (division by 0), a value of 0 is returned for the PSS.
:::

## Overall Accuracy {#sec-tech_performance_indicators_oa}

The Overall Accurary ($OA$) indicates the performance of the model to reproduce the overrun of a threshold [@parajka_spatio-temporal_2008]. Based on the same contingency table as the Pierce Skill 
Score, the $OA$ is computed according to @eq-IND14.

$$
OA = \frac{a + d}{a + b + \ c + d}
$$ {#eq-IND14}

## References {.unnumbered}
