# Performance indicators {#sec-performance_indicators}

The indicators calculated by the Comparator object are based on observed and simulated values. Since the Comparator object is able to compare variables of type flow, height, altitude, power and True/False, the descriptions below only refer to these 2 variables.

## Nash coefficient {#sec-performance_indicators_nash}

The Nash-Sutcliffe criteria (Nash and Sutcliffe, 1970) is used to assess the predictive power of hydrological models (Ajami et al., 2004; Schaefli and al, 2005; Jordan, 2007; Viviroli et al., 2009; García Hernández et al., 2011). It is defined as presented in equation @eq-IND1.

$$
Nash = 1 - \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})^{2}}}{\sum_{t = t_{i}}^{t_{f}}{(X_{ref,t} - {\overline{X}_{ref}})^{2}}}
$$ {#eq-IND1}

with $Nash$: Nash-Sutcliffe model efficiency coefficient \[-\]; $X_{sim,t}$: simulated variable (discharge \[L^3^/T\] or height \[L\]) at time *t*; $X_{ref,t}$ : observed variable (discharge \[L^3^/T\] or height \[L\]) at time *t*; $\overline{X}_{ref}$: average observed variable (discharge \[L^3^/T\] or height \[L\]) for the considered period.

It varies from -∞ to 1, with 1 representing the best performance of the model and zero the same performance than assuming the average of all the observations at each time step.

## Nash coefficient for logarithm values {#sec-performance_indicators_nashlog}

The Nash-Sutcliffe coefficient for logarithm flow values (Nash-ln) is used to assess the hydrological models performance for low values (Krause et al., 2005; Nóbrega et al., 2011). It is defined as presented in equation eq-IND2.

$$
\text{Nash-ln} = 1 - \frac{\sum_{t = t_{i}}^{t_{f}}{(ln(X_{sim,t}) - ln(X_{ref,t}))^{2}}}{\sum_{t = t_{i}}^{t_{f}}{(ln(X_{ref,t}) - ln({\overline{X}_{ref}}))^{2}}}
$$ {#eq-IND2}
  
with $Nash-ln$: Nash-Sutcliffe coefficient for log values \[-\].

It varies from -∞ to 1, with 1 representing the best performance of the model.

## Pearson Correlation Coefficient {#sec-performance_indicators_pearson}

The Pearson correlation coefficient shows the covariability of the simulated and observed values without penalizing for bias (AghaKouchak and Habib, 2010; Wang et al., 2011). It is defined as presented in equation @eq-IND3.

$$
Pearson = \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - {\overline{X}_{sim}}) \cdot (X_{ref,t} - {\overline{X}_{ref}})}}{\sqrt{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - {\overline{X}_{sim}})^{2}} \cdot \sum_{t = t_{i}}^{t_{f}}{(X_{ref,t} - {\overline{X}_{ref}})^{2}}}}
$$ {#eq-IND3}

with $Pearson$: Pearson Correlation Coefficient \[-\]; ${\overline{X}_{sim}}$: average simulated variable (discharge \[L^3^/T\] or height \[L\]) for the considered period.

It varies from -1 to 1, with 1 representing the best performance of the model.

## Kling-Gupta Efficiency {#sec-performance_indicators_klinggupta}

The Kling-Gupta efficiency (Gupta et al., 2009) provides an indicator which facilitates the global analysis based on different components (correlation, bias and variability) for hydrological modelling issues.

Kling et al. (2012) proposed a revised version of this indicator, to ensure that the bias and variability ratios are not cross-correlated. This update is proposed as indicator in RS MINERVE (equation @eq-IND4):

$$
KGE' = 1 - \sqrt{(r - 1)^{2} + (\beta - 1)^{2} + (\gamma - 1)^{2}}
$$ {#eq-IND4}

$$
\beta = \frac{\mu_{s}}{\mu_{o}}
$$ {#eq-IND5}

$$
\gamma = \frac{{CV}_{s}}{{CV}_{o}} = \frac{\sigma_{s}/\mu_{s}}{\sigma_{o}/\mu_{o}}
$$ {#eq-IND6}

with $KGE'$: modified KGE-statistic \[-\]; $r$: correlation coefficient between simulated and reference values \[-\]; $\beta$: bias ratio; $\gamma$: variability ratio \[-\]; $\mu$: mean discharge \[L^3^/T\]; $CV$: coefficient of variation \[-\]; $\sigma$: standard deviation of discharge \[L^3^/T\]; the indices $s$ and $o$ indicate respectively simulated and observed discharge values.

It varies from 0 to 1, with 1 representing the best performance.

## Bias Score {#sec-performance_indicators_biasscore}

The Bias Score (BS) is a symmetric estimation of the match between the average simulation and average observation (Wang et al., 2011). It is defined as presented in equation @eq-IND7.

$$
BS = 1 - \bigg( max(\frac{{\overline{X}}_{sim}}{{\overline{X}}_{ref}};\frac{{\overline{X}}_{ref}}{{\overline{X}}_{sim}}) - 1 \bigg)^2
$$ {#eq-IND7}

with $BS$: Bias Score \[-\].

It varies from -∞ to 1, with 1 representing the best performance of the model.

## Relative Root Mean Square Error {#sec-performance_indicators_rrmse}

The Relative Root Mean Square Error (RRMSE) is defined as the RMSE
normalized to the mean of the observed values (Feyen et al., 2000;
El-Nasr et al., 2005; Heppner et al., 2006) and is presented in
Eq. IND.8.

$$
RRMSE = \frac{\sqrt{\frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})^{2}}}{n}}}{{\overline{X}}_{ref}}
$$ {#eq-IND8}

with $RRMSE$: relative RMSE \[-\]; $n$: number of values \[-\].

It varies from 0 to +∞. The smaller RRMSE, the better the model performance is.

## Relative Volume Bias {#sec-performance_indicators_rvb}

The Relative Volume Bias (RVB), sometimes called differently,
corresponds in this case to the relative error between the simulated and
the observed volumes during the studied period (Ajami and al, 2004;
Schaefli and al, 2005; Moriasi et al., 2007; AghaKouchak and Habib,
2010) according to Eq. IND.9. This indicator is envisaged for the
comparison between observed and simulated discharges.

$$
RVB = \frac{\sum_{t = t_{i}}^{t_{f}}{(X_{sim,t} - X_{ref,t})}}{\sum_{t = t_{i}}^{t_{f}}{(X_{ref,t})}}
$$ {#eq-IND9}

with RVB: relative volume bias between forecast and observation for
the considered period \[-\]; X usually corresponding to the discharge
variable.

The RVB varies from -1 to +∞. An index near to zero indicates a good
performance of the simulation. Negative values are returned when
simulated variable is, in average, smaller than the average of the
observed one (deficit model), while positive values mean the opposite
(overage model).

## Normalized Peak Error {#sec-performance_indicators_npe}

The Normalized Peak Error (NPE) indicates the relative error between the
simulated and the observed maximum values (Masmoudi and Habaieb, 1993;
Sun and al, 2000; Ajami and al, 2004; Gabellani and al, 2007). It is
computed according to IND.10 TO IND.12.

$$
NPE = \frac{S_{\max} - R_{\max}}{R_{\max}}
$$ {#eq-IND10}

$$
S_{\max} = \overset{t_{f}}{\underset{t = t_{i}}{\vee}}Q_{sim,t}
$$ {#eq-IND11}

$$
R_{\max} = \overset{t_{f}}{\underset{t = t_{i}}{\vee}}Q_{ref,t}
$$ {#eq-IND12}

with NPE: relative error between simulated and observed peak value
\[-\]; S~max~ : maximum simulated value (discharge \[L^3^/T\] or height
\[L\]) for the studied period; R~max~ : maximum observed value
(discharge \[L^3^/T\] or height \[L\]) for the studied period.

The NPE varies from -1 to +∞. Negative values are returned when maximum
simulated value is below the observed one, while positive values mean
the opposite. Values near to zero indicate a good performance of
simulated peaks regarding observed ones.

:::{.callout-warning}
The indicator is computed over the entire simulation period and the absolute maximum of the simulated and the observed peaks are considered! This indicator should therefore be used with care when simulating over long periods of time.
:::

## Peirce Skill Score {#sec-performance_indicators_pierce}

The Peirce Skill Score (PSS) indicates the performance of the model to
reproduce the overrun of a threshold (Peirce, 1884; Manzato, 2007).
Based on a contingency table definging the number of cases where the
simulation and the obseration exceed or not the threshold, the PSS is
computed according to IND.13.

$$
PSS = \frac{ad - bc}{(a + c)(b + d)}
$$ {#eq-IND13}

with $a$: the number of cases when both simulation and observation exceed the threshold defined in the Comparator (event); $b$: the number of cases when the simulation exceeds the threshold but not the obseration (false); $c$: the number of cases when the observation exceeds the threshold but not the simulation (miss); $d$: the number of cases when both simulation and obseration are below the threshold (nonevent).

:::{.callout-note}
Remark : If the denominerator equals 0 (division by 0), a value of 0 is returned for the PSS.
:::

## Overall Accuracy {#sec-performance_indicators_oa}

The Overall Accurary (OA) indicates the performance of the model to reproduce the overrun of a threshold (Parajka and Blöschl, 2008). Based on the same contingency table as the Pierce Skill Score, the OA is computed according to equation @eq-IND14.

$$
OA = \frac{a + d}{a + b + \ c + d}
$$ {#eq-IND14}
